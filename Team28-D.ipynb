{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Εργασία στο Μάθημα Αναγνώριση Προτύπων - Μέρος Δ\n",
    "## Ομάδα 28\n",
    "### Ονοματεπώνυμα Φοιτητών:  Μαχμουτάϊ Έλενα, Τσουκαλά Ναταλία "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, our goal to develop a classification algorithm using the `datasetC.csv` as our training set. With 5000 samples, each boasting 400 features and labeled from 1 to 5, our collective task is to implement and train a classification method.\n",
    "\n",
    "Following the training phase, we will apply our honed model to the unlabeled `datasetCTest.csv` test set. Our output will poduce a numpy vector named `labels28`, encapsulating the predictions generated by our collaborative efforts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our first experiment, we decided to train and evaluated a neural network based on our `datasetC.csv` using `TensorFlow` and `Keras`. The dataset is split into training and testing sets, and the neural network architecture is systematically varied by exploring different sizes for two hidden dense layers with ReLU activation functions. The network is trained using the Adam optimizer and sparse categorical cross-entropy loss for 10 epochs, and its performance is evaluated on the test set. TensorBoard is employed to log the training process and facilitate the analysis of model training and performance metrics. The experiment aims to identify the optimal configuration of hidden layer sizes that maximizes accuracy on the given dataset. The results, including test loss and accuracy, are printed for each configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first have to set up the TensorBoard default port."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from keras import layers\n",
    "# from keras.callbacks import TensorBoard\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import time\n",
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# # Load the dataset from the specified path\n",
    "# data = pd.read_csv(r\"D:\\projects\\Pattern-Recognition\\datasetC.csv\", header=None)\n",
    "\n",
    "# # Extract feature matrix (X) and target variable (y) from the dataset\n",
    "# layer_sizes = [10, 64, 128, 256]\n",
    "# data = data.values\n",
    "\n",
    "# X = data[:, :-1]\n",
    "# y = data[:, -1]\n",
    "\n",
    "# # Split the dataset into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "# # Iterate over different layer sizes for the neural network\n",
    "# for layer1_size in layer_sizes:\n",
    "#     for layer2_size in layer_sizes:\n",
    "#         # Create a unique name for the experiment based on layer sizes and current timestamp\n",
    "#         NAME = \"{}-layer1-{}-layer2-{}\".format(layer1_size, layer2_size, int(time.time()))\n",
    "        \n",
    "#         logdir = os.path.join(\"logs\", NAME)\n",
    "#         tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "#         # Create a sequential model (feedforward neural network)\n",
    "#         model = tf.keras.models.Sequential()\n",
    "            \n",
    "#         # Flatten layer to transform input data into a 1D array\n",
    "#         model.add(layers.Flatten(input_shape=(400,)))\n",
    "        \n",
    "#         # First dense layer with ReLU activation\n",
    "#         model.add(layers.Dense(layer1_size, activation='relu'))\n",
    "        \n",
    "#         # Second dense layer with ReLU activation\n",
    "#         model.add(layers.Dense(layer2_size, activation='relu'))\n",
    "        \n",
    "#         # Output layer with softmax activation for multiclass classification\n",
    "#         model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "#         # Compile the model with Adam optimizer, sparse categorical crossentropy loss, and accuracy metric\n",
    "#         model.compile(optimizer='adam',\n",
    "#                       loss='sparse_categorical_crossentropy',\n",
    "#                       metrics=['accuracy'])\n",
    "        \n",
    "#         # Train the model on the training data for 10 epochs, with 30% validation split and TensorBoard callback\n",
    "#         model.fit(X_train, y_train, epochs=10, validation_split=0.3, callbacks=[tensorboard_callback])\n",
    "       \n",
    "#         # Evaluate the trained model on the test set\n",
    "#         test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "#         print(f'Test loss: {test_loss}')\n",
    "#         print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to view our results using Tensorboard we can start the TensorBoard within the notebook using [magics](https://ipython.readthedocs.io/en/stable/interactive/magics.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Tensorboard we notice that our best results in validation accuracy for our first experiment are the following:\n",
    "\n",
    "```\n",
    "|--Validation accuracy--|--Layer1 size--|--Layer2 size--|\n",
    "|      0.8053           |      64       |       128     |\n",
    "|       0.8             |      64       |       10      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this experiment we tried to determined that if by increasing the number of layers in the previous experiment we would notice drastic improvement in our validation accuracy. Thats why we performed our investigation to a 3 Layer Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Clear any logs from previous runs\n",
    "# !rmdir /s /q .\\logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from keras import layers\n",
    "# from keras.callbacks import TensorBoard\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import time\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# data = pd.read_csv(r\"D:\\projects\\Pattern-Recognition\\datasetC.csv\", header=None)\n",
    "\n",
    "# layer_sizes = [10, 64, 128, 256]\n",
    "# data = data.values\n",
    "\n",
    "# X = data[:, :-1]\n",
    "# y = data[:, -1]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "# for layer1_size in layer_sizes:\n",
    "#     for layer2_size in layer_sizes:\n",
    "#         for layer3_size in layer_sizes:\n",
    "#             NAME = \"{}-layer1-{}-layer2-{}-layer3-{}\".format(layer1_size, layer2_size, layer3_size, int(time.time()))\n",
    "#             logdir = os.path.join(\"logs\", NAME)\n",
    "#             tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "#             model = tf.keras.models.Sequential()\n",
    "            \n",
    "#             model.add(layers.Flatten(input_shape=(400,)))\n",
    "#             model.add(layers.Dense(layer1_size, activation='relu'))\n",
    "#             model.add(layers.Dropout(0.5))\n",
    "#             model.add(layers.Dense(layer2_size, activation='relu'))\n",
    "#             model.add(layers.Dropout(0.5))\n",
    "#             model.add(layers.Dense(layer3_size, activation='relu'))\n",
    "#             model.add(layers.Dropout(0.5))\n",
    "#             model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "#             model.compile(optimizer='adam',\n",
    "#                           loss='sparse_categorical_crossentropy',\n",
    "#                           metrics=['accuracy'])\n",
    "            \n",
    "#             model.fit(X_train, y_train, epochs=10, validation_split=0.3, callbacks=[tensorboard_callback])\n",
    "           \n",
    "#             test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "#             print(f'Test loss: {test_loss}')\n",
    "#             print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we start the TensorBoard within the notebook using [magics](https://ipython.readthedocs.io/en/stable/interactive/magics.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Tensorboard we notice that our best results in validation accuracy for our second experience are the following:\n",
    "\n",
    "```\n",
    "|--Validation accuracy--|--Layer1 size--|--Layer2 size--|--Layer3 size--|\n",
    "|       0.824           |      256      |       256     |      128      |\n",
    "|       0.8074          |      256      |       256     |      256      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By performing our second experiment we notice that the accuracy has not increased much by increasing the number of the layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our previous results were pretty much the same we descide to change our layer type and try various different combination. (Need to write this better!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rmdir /s /q .\\logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import necessary libraries\n",
    "# import tensorflow as tf\n",
    "# from keras import layers\n",
    "# from keras.callbacks import TensorBoard\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import time\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # Load data from CSV file\n",
    "# data = pd.read_csv(r\"D:\\projects\\Pattern-Recognition\\datasetC.csv\", header=None)\n",
    "\n",
    "# # Preprocess data by converting it to NumPy array\n",
    "# data = data.values\n",
    "# X = data[:, :-1]\n",
    "# y = data[:, -1]\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "# # Define hyperparameters and architecture variations\n",
    "# layer_sizes = [64, 128, 256]\n",
    "\n",
    "# # Experiment loop for different layer sizes\n",
    "# for layer1_size in layer_sizes:\n",
    "#     for layer2_size in layer_sizes:\n",
    "#         for layer3_size in layer_sizes:\n",
    "#             # Generate a unique name for each experiment based on timestamp\n",
    "#             NAME = \"{}-layer1-{}-layer2-{}-layer3-{}\".format(\n",
    "#                 layer1_size, layer2_size, layer3_size, int(time.time())\n",
    "#             )\n",
    "            \n",
    "#             logdir = os.path.join(\"logs\", NAME)\n",
    "#             tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "#             # Build the sequential model\n",
    "#             model = tf.keras.models.Sequential()\n",
    "#             model.add(layers.Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(400, 1)))\n",
    "#             model.add(layers.MaxPooling1D(pool_size=2))\n",
    "#             model.add(layers.Flatten())\n",
    "#             model.add(layers.Dense(layer1_size, activation='relu'))\n",
    "#             model.add(layers.BatchNormalization())\n",
    "#             model.add(layers.Dropout(0.5))\n",
    "#             model.add(layers.Dense(layer2_size, activation='relu'))\n",
    "#             model.add(layers.BatchNormalization())\n",
    "#             model.add(layers.Dropout(0.5))\n",
    "#             model.add(layers.Dense(layer3_size, activation='relu'))\n",
    "#             model.add(layers.BatchNormalization())\n",
    "#             model.add(layers.Dropout(0.5))\n",
    "#             model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "#             # Compile the model with Adam optimizer and categorical crossentropy loss\n",
    "#             model.compile(optimizer='adam',\n",
    "#                           loss='sparse_categorical_crossentropy',\n",
    "#                           metrics=['accuracy'])\n",
    "\n",
    "#             # Reshape input data for Conv1D layer\n",
    "#             X_train_reshaped = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "#             X_test_reshaped = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "#             # Train the model with 10 epochs, 30% validation split, and TensorBoard callback\n",
    "#             model.fit(X_train_reshaped, y_train, epochs=10, validation_split=0.3, callbacks=[tensorboard_callback])\n",
    "\n",
    "#             # Evaluate the model on the test set\n",
    "#             test_loss, test_acc = model.evaluate(X_test_reshaped, y_test)\n",
    "            \n",
    "#             # Print results for each experiment\n",
    "#             print(f'Model: {NAME}')\n",
    "#             print(f'Test loss: {test_loss}')\n",
    "#             print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we start the TensorBoard within the notebook using [magics](https://ipython.readthedocs.io/en/stable/interactive/magics.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Tensorboard we notice that our best results in validation accuracy for our third experience are the following:\n",
    "\n",
    "```\n",
    "|--Validation accuracy--|--Layer1 size--|--Layer2 size--|--Layer3 size--|\n",
    "|       0.8035          |      256      |       128     |      64       |\n",
    "|       0.801           |      128      |       64      |      128      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that there is not much accuracy increase and the results are lower than before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourth Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the file specified.\n"
     ]
    }
   ],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rmdir /s /q .\\logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "55/55 [==============================] - 38s 551ms/step - loss: 1.7944 - accuracy: 0.2046 - val_loss: 1.6379 - val_accuracy: 0.1773\n",
      "Epoch 2/10\n",
      "55/55 [==============================] - 28s 507ms/step - loss: 1.6296 - accuracy: 0.2080 - val_loss: 1.6170 - val_accuracy: 0.2307\n",
      "Epoch 3/10\n",
      "55/55 [==============================] - 28s 508ms/step - loss: 1.6185 - accuracy: 0.2149 - val_loss: 1.6224 - val_accuracy: 0.2307\n",
      "Epoch 4/10\n",
      "55/55 [==============================] - 28s 511ms/step - loss: 1.6206 - accuracy: 0.1891 - val_loss: 1.6113 - val_accuracy: 0.2067\n",
      "Epoch 5/10\n",
      "55/55 [==============================] - 28s 503ms/step - loss: 1.6183 - accuracy: 0.2029 - val_loss: 1.6145 - val_accuracy: 0.2067\n",
      "Epoch 6/10\n",
      "55/55 [==============================] - 29s 517ms/step - loss: 1.6157 - accuracy: 0.2149 - val_loss: 1.6167 - val_accuracy: 0.2067\n",
      "Epoch 7/10\n",
      "55/55 [==============================] - 28s 504ms/step - loss: 1.6166 - accuracy: 0.1846 - val_loss: 1.6158 - val_accuracy: 0.2013\n",
      "Epoch 8/10\n",
      "55/55 [==============================] - 28s 508ms/step - loss: 1.6161 - accuracy: 0.1977 - val_loss: 1.6122 - val_accuracy: 0.2307\n",
      "Epoch 9/10\n",
      "55/55 [==============================] - 28s 509ms/step - loss: 1.6154 - accuracy: 0.2017 - val_loss: 1.6158 - val_accuracy: 0.2013\n",
      "Epoch 10/10\n",
      "55/55 [==============================] - 28s 508ms/step - loss: 1.6137 - accuracy: 0.1989 - val_loss: 1.6128 - val_accuracy: 0.2307\n",
      "79/79 [==============================] - 12s 149ms/step - loss: 1.6153 - accuracy: 0.2292\n",
      "Model: 64-layer1-64-layer2-64-layer3-1704215596\n",
      "Test loss: 1.615333080291748\n",
      "Test accuracy: 0.22920000553131104\n",
      "Epoch 1/10\n",
      "55/55 [==============================] - 45s 713ms/step - loss: 1.7429 - accuracy: 0.2029 - val_loss: 1.6110 - val_accuracy: 0.1960\n",
      "Epoch 2/10\n",
      "55/55 [==============================] - 38s 694ms/step - loss: 1.5903 - accuracy: 0.2766 - val_loss: 1.6180 - val_accuracy: 0.2307\n",
      "Epoch 3/10\n",
      "55/55 [==============================] - 38s 695ms/step - loss: 1.6185 - accuracy: 0.2217 - val_loss: 1.6041 - val_accuracy: 0.1987\n",
      "Epoch 4/10\n",
      "55/55 [==============================] - 39s 704ms/step - loss: 1.6254 - accuracy: 0.2200 - val_loss: 1.6263 - val_accuracy: 0.2080\n",
      "Epoch 5/10\n",
      "55/55 [==============================] - 39s 708ms/step - loss: 1.6297 - accuracy: 0.2154 - val_loss: 1.6166 - val_accuracy: 0.1867\n",
      "Epoch 6/10\n",
      "55/55 [==============================] - 40s 726ms/step - loss: 1.6192 - accuracy: 0.2137 - val_loss: 1.6059 - val_accuracy: 0.2280\n",
      "Epoch 7/10\n",
      "55/55 [==============================] - 39s 706ms/step - loss: 1.6166 - accuracy: 0.2063 - val_loss: 1.6156 - val_accuracy: 0.1773\n",
      "Epoch 8/10\n",
      "55/55 [==============================] - 39s 711ms/step - loss: 1.6157 - accuracy: 0.2217 - val_loss: 1.6113 - val_accuracy: 0.2453\n",
      "Epoch 9/10\n",
      "55/55 [==============================] - 39s 711ms/step - loss: 1.6223 - accuracy: 0.2143 - val_loss: 1.6095 - val_accuracy: 0.2280\n",
      "Epoch 10/10\n",
      "55/55 [==============================] - 39s 704ms/step - loss: 1.6097 - accuracy: 0.2411 - val_loss: 1.5628 - val_accuracy: 0.3093\n",
      "79/79 [==============================] - 16s 203ms/step - loss: 1.5541 - accuracy: 0.3088\n",
      "Model: 64-layer1-64-layer2-128-layer3-1704215898\n",
      "Test loss: 1.5541006326675415\n",
      "Test accuracy: 0.30880001187324524\n",
      "Epoch 1/10\n",
      "55/55 [==============================] - 103s 2s/step - loss: 1.6835 - accuracy: 0.2526 - val_loss: 1.5428 - val_accuracy: 0.3320\n",
      "Epoch 2/10\n",
      "55/55 [==============================] - 98s 2s/step - loss: 1.5348 - accuracy: 0.3126 - val_loss: 1.5135 - val_accuracy: 0.3040\n",
      "Epoch 3/10\n",
      "55/55 [==============================] - 100s 2s/step - loss: 1.5014 - accuracy: 0.3234 - val_loss: 1.4847 - val_accuracy: 0.2933\n",
      "Epoch 4/10\n",
      "55/55 [==============================] - 100s 2s/step - loss: 1.4808 - accuracy: 0.3463 - val_loss: 1.4686 - val_accuracy: 0.3360\n",
      "Epoch 5/10\n",
      "55/55 [==============================] - 98s 2s/step - loss: 1.5114 - accuracy: 0.3314 - val_loss: 1.5452 - val_accuracy: 0.3293\n",
      "Epoch 6/10\n",
      "55/55 [==============================] - 98s 2s/step - loss: 1.4834 - accuracy: 0.3457 - val_loss: 1.4983 - val_accuracy: 0.3307\n",
      "Epoch 7/10\n",
      "55/55 [==============================] - 99s 2s/step - loss: 1.4543 - accuracy: 0.3743 - val_loss: 1.4832 - val_accuracy: 0.3480\n",
      "Epoch 8/10\n",
      "55/55 [==============================] - 98s 2s/step - loss: 1.4567 - accuracy: 0.3566 - val_loss: 1.4615 - val_accuracy: 0.3560\n",
      "Epoch 9/10\n",
      "55/55 [==============================] - 98s 2s/step - loss: 1.4691 - accuracy: 0.3537 - val_loss: 1.4933 - val_accuracy: 0.3613\n",
      "Epoch 10/10\n",
      "55/55 [==============================] - 97s 2s/step - loss: 1.4625 - accuracy: 0.3486 - val_loss: 1.4993 - val_accuracy: 0.3533\n",
      "79/79 [==============================] - 32s 408ms/step - loss: 1.4710 - accuracy: 0.3552\n",
      "Model: 64-layer1-64-layer2-256-layer3-1704216309\n",
      "Test loss: 1.4709874391555786\n",
      "Test accuracy: 0.35519999265670776\n",
      "Epoch 1/10\n",
      "55/55 [==============================] - 57s 770ms/step - loss: 1.7462 - accuracy: 0.1931 - val_loss: 1.6241 - val_accuracy: 0.1840\n",
      "Epoch 2/10\n",
      "55/55 [==============================] - 42s 763ms/step - loss: 1.6253 - accuracy: 0.1994 - val_loss: 1.6278 - val_accuracy: 0.2013\n",
      "Epoch 3/10\n",
      "55/55 [==============================] - 42s 761ms/step - loss: 1.6149 - accuracy: 0.2177 - val_loss: 1.5940 - val_accuracy: 0.2960\n",
      "Epoch 4/10\n",
      "55/55 [==============================] - 42s 763ms/step - loss: 1.5811 - accuracy: 0.2886 - val_loss: 1.6190 - val_accuracy: 0.1920\n",
      "Epoch 5/10\n",
      "55/55 [==============================] - 42s 770ms/step - loss: 1.6139 - accuracy: 0.2126 - val_loss: 1.6161 - val_accuracy: 0.1787\n",
      "Epoch 6/10\n",
      "55/55 [==============================] - 42s 766ms/step - loss: 1.6134 - accuracy: 0.2029 - val_loss: 1.6080 - val_accuracy: 0.2320\n",
      "Epoch 7/10\n",
      "55/55 [==============================] - 42s 765ms/step - loss: 1.6168 - accuracy: 0.2029 - val_loss: 1.6128 - val_accuracy: 0.2000\n",
      "Epoch 8/10\n",
      "55/55 [==============================] - 45s 822ms/step - loss: 1.6110 - accuracy: 0.1994 - val_loss: 1.5975 - val_accuracy: 0.2453\n",
      "Epoch 9/10\n",
      "55/55 [==============================] - 44s 808ms/step - loss: 1.5968 - accuracy: 0.2423 - val_loss: 1.6170 - val_accuracy: 0.2040\n",
      "Epoch 10/10\n",
      "55/55 [==============================] - 44s 805ms/step - loss: 1.5887 - accuracy: 0.2423 - val_loss: 1.6052 - val_accuracy: 0.2573\n",
      "79/79 [==============================] - 18s 221ms/step - loss: 1.5962 - accuracy: 0.2548\n",
      "Model: 64-layer1-128-layer2-64-layer3-1704217331\n",
      "Test loss: 1.5962369441986084\n",
      "Test accuracy: 0.2547999918460846\n",
      "Epoch 1/10\n",
      "55/55 [==============================] - 65s 1s/step - loss: 1.7287 - accuracy: 0.2469 - val_loss: 1.5881 - val_accuracy: 0.2720\n",
      "Epoch 2/10\n",
      "55/55 [==============================] - 60s 1s/step - loss: 1.5585 - accuracy: 0.3000 - val_loss: 1.6065 - val_accuracy: 0.2747\n",
      "Epoch 3/10\n",
      "55/55 [==============================] - 59s 1s/step - loss: 1.6147 - accuracy: 0.2166 - val_loss: 1.6013 - val_accuracy: 0.2453\n",
      "Epoch 4/10\n",
      "55/55 [==============================] - 59s 1s/step - loss: 1.6185 - accuracy: 0.2154 - val_loss: 1.6555 - val_accuracy: 0.2400\n",
      "Epoch 5/10\n",
      "55/55 [==============================] - 59s 1s/step - loss: 1.6169 - accuracy: 0.2154 - val_loss: 1.6109 - val_accuracy: 0.2293\n",
      "Epoch 6/10\n",
      "55/55 [==============================] - 58s 1s/step - loss: 1.6129 - accuracy: 0.2051 - val_loss: 1.6093 - val_accuracy: 0.1853\n",
      "Epoch 7/10\n",
      "55/55 [==============================] - 59s 1s/step - loss: 1.6125 - accuracy: 0.2017 - val_loss: 1.6191 - val_accuracy: 0.1933\n",
      "Epoch 8/10\n",
      "55/55 [==============================] - 59s 1s/step - loss: 1.6233 - accuracy: 0.2131 - val_loss: 1.6048 - val_accuracy: 0.2013\n",
      "Epoch 9/10\n",
      "55/55 [==============================] - 58s 1s/step - loss: 1.6105 - accuracy: 0.2166 - val_loss: 1.6140 - val_accuracy: 0.2320\n",
      "Epoch 10/10\n",
      "55/55 [==============================] - 62s 1s/step - loss: 1.6168 - accuracy: 0.2189 - val_loss: 1.6078 - val_accuracy: 0.2413\n",
      "79/79 [==============================] - 23s 286ms/step - loss: 1.6139 - accuracy: 0.2360\n",
      "Model: 64-layer1-128-layer2-128-layer3-1704217792\n",
      "Test loss: 1.6139123439788818\n",
      "Test accuracy: 0.23600000143051147\n",
      "Epoch 1/10\n",
      "55/55 [==============================] - 116s 2s/step - loss: 1.6925 - accuracy: 0.2429 - val_loss: 1.5346 - val_accuracy: 0.3307\n",
      "Epoch 2/10\n",
      "55/55 [==============================] - 124s 2s/step - loss: 1.5372 - accuracy: 0.2817 - val_loss: 1.4931 - val_accuracy: 0.3520\n",
      "Epoch 3/10\n",
      "55/55 [==============================] - 152s 3s/step - loss: 1.5421 - accuracy: 0.2971 - val_loss: 1.5361 - val_accuracy: 0.3520\n",
      "Epoch 4/10\n",
      "55/55 [==============================] - 96s 2s/step - loss: 1.4909 - accuracy: 0.3303 - val_loss: 1.4549 - val_accuracy: 0.3640\n",
      "Epoch 5/10\n",
      "55/55 [==============================] - 98s 2s/step - loss: 1.5059 - accuracy: 0.3326 - val_loss: 1.4803 - val_accuracy: 0.3427\n",
      "Epoch 6/10\n",
      "55/55 [==============================] - 97s 2s/step - loss: 1.4681 - accuracy: 0.3486 - val_loss: 1.4411 - val_accuracy: 0.3587\n",
      "Epoch 7/10\n",
      "55/55 [==============================] - 99s 2s/step - loss: 1.4556 - accuracy: 0.3800 - val_loss: 1.4845 - val_accuracy: 0.3667\n",
      "Epoch 8/10\n",
      "55/55 [==============================] - 99s 2s/step - loss: 1.4476 - accuracy: 0.3674 - val_loss: 1.4741 - val_accuracy: 0.3493\n",
      "Epoch 9/10\n",
      "55/55 [==============================] - 99s 2s/step - loss: 1.4743 - accuracy: 0.3583 - val_loss: 1.5091 - val_accuracy: 0.3387\n",
      "Epoch 10/10\n",
      "55/55 [==============================] - 97s 2s/step - loss: 1.4786 - accuracy: 0.3429 - val_loss: 1.4566 - val_accuracy: 0.3533\n",
      "79/79 [==============================] - 39s 493ms/step - loss: 1.4387 - accuracy: 0.3644\n",
      "Model: 64-layer1-128-layer2-256-layer3-1704218413\n",
      "Test loss: 1.4387004375457764\n",
      "Test accuracy: 0.3643999993801117\n",
      "Epoch 1/10\n",
      "55/55 [==============================] - 133s 2s/step - loss: 1.7202 - accuracy: 0.2211 - val_loss: 1.6288 - val_accuracy: 0.2067\n",
      "Epoch 2/10\n",
      "55/55 [==============================] - 129s 2s/step - loss: 1.6421 - accuracy: 0.2040 - val_loss: 1.6353 - val_accuracy: 0.1840\n",
      "Epoch 3/10\n",
      "55/55 [==============================] - 129s 2s/step - loss: 1.6182 - accuracy: 0.2074 - val_loss: 1.6143 - val_accuracy: 0.2013\n",
      "Epoch 4/10\n",
      "55/55 [==============================] - 127s 2s/step - loss: 1.6164 - accuracy: 0.2086 - val_loss: 1.6249 - val_accuracy: 0.2013\n",
      "Epoch 5/10\n",
      "55/55 [==============================] - 127s 2s/step - loss: 1.6178 - accuracy: 0.2177 - val_loss: 1.6192 - val_accuracy: 0.2013\n",
      "Epoch 6/10\n",
      "55/55 [==============================] - 127s 2s/step - loss: 1.6142 - accuracy: 0.1994 - val_loss: 1.6068 - val_accuracy: 0.2307\n",
      "Epoch 7/10\n",
      "55/55 [==============================] - 127s 2s/step - loss: 1.6120 - accuracy: 0.2063 - val_loss: 1.6216 - val_accuracy: 0.1773\n",
      "Epoch 8/10\n",
      "55/55 [==============================] - 128s 2s/step - loss: 1.6119 - accuracy: 0.2120 - val_loss: 1.6123 - val_accuracy: 0.2013\n",
      "Epoch 9/10\n",
      "55/55 [==============================] - 128s 2s/step - loss: 1.6093 - accuracy: 0.2006 - val_loss: 1.6221 - val_accuracy: 0.1840\n",
      "Epoch 10/10\n",
      "55/55 [==============================] - 129s 2s/step - loss: 1.6143 - accuracy: 0.2097 - val_loss: 1.6126 - val_accuracy: 0.2013\n",
      "79/79 [==============================] - 39s 492ms/step - loss: 1.6098 - accuracy: 0.2060\n",
      "Model: 64-layer1-256-layer2-64-layer3-1704219530\n",
      "Test loss: 1.6098337173461914\n",
      "Test accuracy: 0.20600000023841858\n",
      "Epoch 1/10\n",
      "55/55 [==============================] - 148s 3s/step - loss: 1.7302 - accuracy: 0.2103 - val_loss: 1.6476 - val_accuracy: 0.2013\n",
      "Epoch 2/10\n",
      "55/55 [==============================] - 142s 3s/step - loss: 1.6238 - accuracy: 0.1983 - val_loss: 1.6134 - val_accuracy: 0.1840\n",
      "Epoch 3/10\n",
      "55/55 [==============================] - 143s 3s/step - loss: 1.6196 - accuracy: 0.2086 - val_loss: 1.6181 - val_accuracy: 0.2427\n",
      "Epoch 4/10\n",
      "55/55 [==============================] - 158s 3s/step - loss: 1.6179 - accuracy: 0.2166 - val_loss: 1.6274 - val_accuracy: 0.2307\n",
      "Epoch 5/10\n",
      "55/55 [==============================] - 288s 5s/step - loss: 1.6202 - accuracy: 0.2091 - val_loss: 1.6115 - val_accuracy: 0.2307\n",
      "Epoch 6/10\n",
      "55/55 [==============================] - 232s 4s/step - loss: 1.6204 - accuracy: 0.2097 - val_loss: 1.6081 - val_accuracy: 0.2013\n",
      "Epoch 7/10\n",
      "55/55 [==============================] - 270s 5s/step - loss: 1.6171 - accuracy: 0.2211 - val_loss: 1.6382 - val_accuracy: 0.2027\n",
      "Epoch 8/10\n",
      "55/55 [==============================] - 255s 5s/step - loss: 1.6228 - accuracy: 0.2234 - val_loss: 1.6314 - val_accuracy: 0.2307\n",
      "Epoch 9/10\n",
      "55/55 [==============================] - 233s 4s/step - loss: 1.6218 - accuracy: 0.2120 - val_loss: 1.6109 - val_accuracy: 0.1840\n",
      "Epoch 10/10\n",
      "55/55 [==============================] - 237s 4s/step - loss: 1.6186 - accuracy: 0.2080 - val_loss: 1.6079 - val_accuracy: 0.2307\n",
      "79/79 [==============================] - 70s 885ms/step - loss: 1.6075 - accuracy: 0.2292\n",
      "Model: 64-layer1-256-layer2-128-layer3-1704220854\n",
      "Test loss: 1.607468843460083\n",
      "Test accuracy: 0.22920000553131104\n",
      "Epoch 1/10\n",
      "55/55 [==============================] - 565s 10s/step - loss: 1.7474 - accuracy: 0.1989 - val_loss: 1.6629 - val_accuracy: 0.2280\n",
      "Epoch 2/10\n",
      "55/55 [==============================] - 581s 11s/step - loss: 1.6340 - accuracy: 0.2166 - val_loss: 1.6427 - val_accuracy: 0.2373\n",
      "Epoch 3/10\n",
      "55/55 [==============================] - 631s 12s/step - loss: 1.6329 - accuracy: 0.1960 - val_loss: 1.6283 - val_accuracy: 0.1840\n",
      "Epoch 4/10\n",
      "55/55 [==============================] - 727s 13s/step - loss: 1.6246 - accuracy: 0.2229 - val_loss: 1.5731 - val_accuracy: 0.2853\n",
      "Epoch 5/10\n",
      "55/55 [==============================] - 504s 9s/step - loss: 1.5969 - accuracy: 0.2611 - val_loss: 1.5628 - val_accuracy: 0.2960\n",
      "Epoch 6/10\n",
      "55/55 [==============================] - 596s 11s/step - loss: 1.5841 - accuracy: 0.2640 - val_loss: 1.5443 - val_accuracy: 0.3000\n",
      "Epoch 7/10\n",
      "55/55 [==============================] - 317s 6s/step - loss: 1.5863 - accuracy: 0.2611 - val_loss: 1.5412 - val_accuracy: 0.2840\n",
      "Epoch 8/10\n",
      "55/55 [==============================] - 309s 6s/step - loss: 1.4964 - accuracy: 0.3274 - val_loss: 1.5121 - val_accuracy: 0.2947\n",
      "Epoch 9/10\n",
      "55/55 [==============================] - 331s 6s/step - loss: 1.4907 - accuracy: 0.3383 - val_loss: 1.4949 - val_accuracy: 0.3573\n",
      "Epoch 10/10\n",
      "55/55 [==============================] - 311s 6s/step - loss: 1.4949 - accuracy: 0.3411 - val_loss: 1.5010 - val_accuracy: 0.3067\n",
      "79/79 [==============================] - 70s 883ms/step - loss: 1.4666 - accuracy: 0.3308\n",
      "Model: 64-layer1-256-layer2-256-layer3-1704223033\n",
      "Test loss: 1.4666355848312378\n",
      "Test accuracy: 0.33079999685287476\n",
      "Epoch 1/10\n",
      "55/55 [==============================] - 57s 933ms/step - loss: 1.7728 - accuracy: 0.1869 - val_loss: 1.6385 - val_accuracy: 0.1840\n",
      "Epoch 2/10\n",
      "55/55 [==============================] - 51s 921ms/step - loss: 1.6266 - accuracy: 0.2097 - val_loss: 1.6269 - val_accuracy: 0.2013\n",
      "Epoch 3/10\n",
      "55/55 [==============================] - 52s 954ms/step - loss: 1.6164 - accuracy: 0.2297 - val_loss: 1.6412 - val_accuracy: 0.1773\n",
      "Epoch 4/10\n",
      "55/55 [==============================] - 57s 1s/step - loss: 1.6260 - accuracy: 0.1983 - val_loss: 1.6146 - val_accuracy: 0.2013\n",
      "Epoch 5/10\n",
      "55/55 [==============================] - 51s 936ms/step - loss: 1.6172 - accuracy: 0.1971 - val_loss: 1.6119 - val_accuracy: 0.2307\n",
      "Epoch 6/10\n",
      "55/55 [==============================] - 55s 1s/step - loss: 1.6141 - accuracy: 0.2114 - val_loss: 1.6167 - val_accuracy: 0.2013\n",
      "Epoch 7/10\n",
      "55/55 [==============================] - 58s 1s/step - loss: 1.6211 - accuracy: 0.1891 - val_loss: 1.6156 - val_accuracy: 0.2013\n",
      "Epoch 8/10\n",
      "55/55 [==============================] - 52s 953ms/step - loss: 1.6154 - accuracy: 0.2046 - val_loss: 1.6104 - val_accuracy: 0.2307\n",
      "Epoch 9/10\n",
      "55/55 [==============================] - 52s 948ms/step - loss: 1.6136 - accuracy: 0.2069 - val_loss: 1.6107 - val_accuracy: 0.2307\n",
      "Epoch 10/10\n",
      "55/55 [==============================] - 56s 1s/step - loss: 1.6129 - accuracy: 0.2086 - val_loss: 1.6204 - val_accuracy: 0.2307\n",
      "79/79 [==============================] - 27s 345ms/step - loss: 1.6129 - accuracy: 0.2292\n",
      "Model: 128-layer1-64-layer2-64-layer3-1704227978\n",
      "Test loss: 1.6129106283187866\n",
      "Test accuracy: 0.22920000553131104\n",
      "Epoch 1/10\n",
      "55/55 [==============================] - 104s 1s/step - loss: 1.7227 - accuracy: 0.2486 - val_loss: 1.6049 - val_accuracy: 0.2987\n",
      "Epoch 2/10\n",
      "55/55 [==============================] - 80s 1s/step - loss: 1.5395 - accuracy: 0.3120 - val_loss: 1.5038 - val_accuracy: 0.3013\n",
      "Epoch 3/10\n",
      "55/55 [==============================] - 80s 1s/step - loss: 1.5105 - accuracy: 0.3234 - val_loss: 1.4832 - val_accuracy: 0.3387\n",
      "Epoch 4/10\n",
      "55/55 [==============================] - 82s 2s/step - loss: 1.5608 - accuracy: 0.3017 - val_loss: 1.5604 - val_accuracy: 0.3147\n",
      "Epoch 5/10\n",
      "55/55 [==============================] - 78s 1s/step - loss: 1.4937 - accuracy: 0.3526 - val_loss: 1.4751 - val_accuracy: 0.3520\n",
      "Epoch 6/10\n",
      "55/55 [==============================] - 80s 1s/step - loss: 1.4725 - accuracy: 0.3491 - val_loss: 1.4817 - val_accuracy: 0.3400\n",
      "Epoch 7/10\n",
      "55/55 [==============================] - 84s 2s/step - loss: 1.4786 - accuracy: 0.3411 - val_loss: 1.4732 - val_accuracy: 0.3520\n",
      "Epoch 8/10\n",
      "55/55 [==============================] - 78s 1s/step - loss: 1.4749 - accuracy: 0.3474 - val_loss: 1.4576 - val_accuracy: 0.3573\n",
      "Epoch 9/10\n",
      "55/55 [==============================] - 81s 1s/step - loss: 1.4532 - accuracy: 0.3560 - val_loss: 1.4545 - val_accuracy: 0.3520\n",
      "Epoch 10/10\n",
      "55/55 [==============================] - 78s 1s/step - loss: 1.4456 - accuracy: 0.3674 - val_loss: 1.4308 - val_accuracy: 0.3707\n",
      "79/79 [==============================] - 32s 407ms/step - loss: 1.4305 - accuracy: 0.3780\n",
      "Model: 128-layer1-64-layer2-128-layer3-1704228551\n",
      "Test loss: 1.4305163621902466\n",
      "Test accuracy: 0.3779999911785126\n",
      "Epoch 1/10\n",
      "55/55 [==============================] - 153s 3s/step - loss: 1.6940 - accuracy: 0.2246 - val_loss: 1.6409 - val_accuracy: 0.2067\n",
      "Epoch 2/10\n",
      "55/55 [==============================] - 131s 2s/step - loss: 1.6321 - accuracy: 0.2074 - val_loss: 1.6128 - val_accuracy: 0.2333\n",
      "Epoch 3/10\n",
      "55/55 [==============================] - 132s 2s/step - loss: 1.6326 - accuracy: 0.1954 - val_loss: 1.6226 - val_accuracy: 0.2307\n",
      "Epoch 4/10\n",
      "55/55 [==============================] - 134s 2s/step - loss: 1.6244 - accuracy: 0.1817 - val_loss: 1.6318 - val_accuracy: 0.2347\n",
      "Epoch 5/10\n",
      "55/55 [==============================] - 140s 3s/step - loss: 1.6194 - accuracy: 0.2011 - val_loss: 1.6012 - val_accuracy: 0.2027\n",
      "Epoch 6/10\n",
      "55/55 [==============================] - 137s 2s/step - loss: 1.6161 - accuracy: 0.2074 - val_loss: 1.6108 - val_accuracy: 0.2067\n",
      "Epoch 7/10\n",
      "55/55 [==============================] - 167s 3s/step - loss: 1.6085 - accuracy: 0.2166 - val_loss: 1.5753 - val_accuracy: 0.2880\n",
      "Epoch 8/10\n",
      "55/55 [==============================] - 223s 4s/step - loss: 1.6096 - accuracy: 0.2366 - val_loss: 1.6253 - val_accuracy: 0.2320\n",
      "Epoch 9/10\n",
      "55/55 [==============================] - 233s 4s/step - loss: 1.6184 - accuracy: 0.2109 - val_loss: 1.6233 - val_accuracy: 0.2013\n",
      "Epoch 10/10\n",
      "55/55 [==============================] - 242s 4s/step - loss: 1.6198 - accuracy: 0.2040 - val_loss: 1.6095 - val_accuracy: 0.2013\n",
      "79/79 [==============================] - 75s 955ms/step - loss: 1.6107 - accuracy: 0.2060\n",
      "Model: 128-layer1-64-layer2-256-layer3-1704229411\n",
      "Test loss: 1.6106904745101929\n",
      "Test accuracy: 0.20600000023841858\n",
      "Epoch 1/10\n",
      "55/55 [==============================] - 158s 3s/step - loss: 1.7495 - accuracy: 0.1966 - val_loss: 1.6353 - val_accuracy: 0.2307\n",
      "Epoch 2/10\n",
      "55/55 [==============================] - 134s 2s/step - loss: 1.6267 - accuracy: 0.2057 - val_loss: 1.6112 - val_accuracy: 0.2013\n",
      "Epoch 3/10\n",
      "55/55 [==============================] - 154s 3s/step - loss: 1.6159 - accuracy: 0.2154 - val_loss: 1.6310 - val_accuracy: 0.2067\n",
      "Epoch 4/10\n",
      "55/55 [==============================] - 142s 3s/step - loss: 1.6228 - accuracy: 0.1989 - val_loss: 1.6257 - val_accuracy: 0.1840\n",
      "Epoch 5/10\n",
      "55/55 [==============================] - 138s 2s/step - loss: 1.6154 - accuracy: 0.2103 - val_loss: 1.6197 - val_accuracy: 0.1773\n",
      "Epoch 6/10\n",
      "55/55 [==============================] - 145s 3s/step - loss: 1.6170 - accuracy: 0.2091 - val_loss: 1.6172 - val_accuracy: 0.1773\n",
      "Epoch 7/10\n",
      "55/55 [==============================] - 138s 3s/step - loss: 1.6096 - accuracy: 0.2217 - val_loss: 1.6243 - val_accuracy: 0.1773\n",
      "Epoch 8/10\n",
      "55/55 [==============================] - 105s 2s/step - loss: 1.6162 - accuracy: 0.2177 - val_loss: 1.6107 - val_accuracy: 0.2307\n",
      "Epoch 9/10\n",
      "55/55 [==============================] - 91s 2s/step - loss: 1.6145 - accuracy: 0.1931 - val_loss: 1.6164 - val_accuracy: 0.2013\n",
      "Epoch 10/10\n",
      "55/55 [==============================] - 89s 2s/step - loss: 1.6149 - accuracy: 0.2137 - val_loss: 1.6133 - val_accuracy: 0.1720\n",
      "79/79 [==============================] - 45s 559ms/step - loss: 1.6098 - accuracy: 0.2016\n",
      "Model: 128-layer1-128-layer2-64-layer3-1704231181\n",
      "Test loss: 1.6097835302352905\n",
      "Test accuracy: 0.20160000026226044\n",
      "Epoch 1/10\n",
      "55/55 [==============================] - 128s 2s/step - loss: 1.7340 - accuracy: 0.2057 - val_loss: 1.6188 - val_accuracy: 0.2307\n",
      "Epoch 2/10\n",
      "55/55 [==============================] - 118s 2s/step - loss: 1.6291 - accuracy: 0.1931 - val_loss: 1.6185 - val_accuracy: 0.2307\n",
      "Epoch 3/10\n",
      "55/55 [==============================] - 202s 4s/step - loss: 1.6344 - accuracy: 0.1960 - val_loss: 1.6139 - val_accuracy: 0.2307\n",
      "Epoch 4/10\n",
      "55/55 [==============================] - 200s 4s/step - loss: 1.6274 - accuracy: 0.2051 - val_loss: 1.6161 - val_accuracy: 0.2040\n",
      "Epoch 5/10\n",
      "55/55 [==============================] - 180s 3s/step - loss: 1.6370 - accuracy: 0.2057 - val_loss: 1.6100 - val_accuracy: 0.1880\n",
      "Epoch 6/10\n",
      "55/55 [==============================] - 178s 3s/step - loss: 1.6281 - accuracy: 0.1909 - val_loss: 1.6169 - val_accuracy: 0.2013\n",
      "Epoch 7/10\n",
      "55/55 [==============================] - 167s 3s/step - loss: 1.6183 - accuracy: 0.2017 - val_loss: 1.6207 - val_accuracy: 0.2080\n",
      "Epoch 8/10\n",
      "55/55 [==============================] - 124s 2s/step - loss: 1.6241 - accuracy: 0.2051 - val_loss: 1.6352 - val_accuracy: 0.2307\n",
      "Epoch 9/10\n",
      "55/55 [==============================] - 124s 2s/step - loss: 1.5980 - accuracy: 0.2640 - val_loss: 1.6668 - val_accuracy: 0.2187\n",
      "Epoch 10/10\n",
      "55/55 [==============================] - 125s 2s/step - loss: 1.5927 - accuracy: 0.2617 - val_loss: 1.5486 - val_accuracy: 0.2800\n",
      "79/79 [==============================] - 40s 503ms/step - loss: 1.5419 - accuracy: 0.2900\n",
      "Model: 128-layer1-128-layer2-128-layer3-1704232523\n",
      "Test loss: 1.5419282913208008\n",
      "Test accuracy: 0.28999999165534973\n",
      "Epoch 1/10\n",
      "55/55 [==============================] - 186s 3s/step - loss: 1.7038 - accuracy: 0.2103 - val_loss: 1.5750 - val_accuracy: 0.2547\n",
      "Epoch 2/10\n",
      "55/55 [==============================] - 170s 3s/step - loss: 1.6324 - accuracy: 0.2686 - val_loss: 1.6409 - val_accuracy: 0.2013\n",
      "Epoch 3/10\n",
      "55/55 [==============================] - 168s 3s/step - loss: 1.6250 - accuracy: 0.2097 - val_loss: 1.6216 - val_accuracy: 0.2067\n",
      "Epoch 4/10\n",
      "55/55 [==============================] - 168s 3s/step - loss: 1.6238 - accuracy: 0.2046 - val_loss: 1.6120 - val_accuracy: 0.2013\n",
      "Epoch 5/10\n",
      "55/55 [==============================] - 168s 3s/step - loss: 1.6225 - accuracy: 0.2097 - val_loss: 1.6165 - val_accuracy: 0.2307\n",
      "Epoch 6/10\n",
      "55/55 [==============================] - 169s 3s/step - loss: 1.6210 - accuracy: 0.1954 - val_loss: 1.6102 - val_accuracy: 0.2013\n",
      "Epoch 7/10\n",
      "55/55 [==============================] - 169s 3s/step - loss: 1.6187 - accuracy: 0.1971 - val_loss: 1.6277 - val_accuracy: 0.2307\n",
      "Epoch 8/10\n",
      "55/55 [==============================] - 191s 3s/step - loss: 1.6195 - accuracy: 0.2057 - val_loss: 1.6131 - val_accuracy: 0.2307\n",
      "Epoch 9/10\n",
      "55/55 [==============================] - 279s 5s/step - loss: 1.6144 - accuracy: 0.2086 - val_loss: 1.6128 - val_accuracy: 0.2013\n",
      "Epoch 10/10\n",
      "55/55 [==============================] - 277s 5s/step - loss: 1.6164 - accuracy: 0.2103 - val_loss: 1.6212 - val_accuracy: 0.2013\n",
      "79/79 [==============================] - 100s 1s/step - loss: 1.6300 - accuracy: 0.2060\n",
      "Model: 128-layer1-128-layer2-256-layer3-1704234113\n",
      "Test loss: 1.629966378211975\n",
      "Test accuracy: 0.20600000023841858\n",
      "Epoch 1/10\n",
      "55/55 [==============================] - 173s 3s/step - loss: 1.7594 - accuracy: 0.2006 - val_loss: 1.7035 - val_accuracy: 0.1787\n",
      "Epoch 2/10\n",
      "55/55 [==============================] - 158s 3s/step - loss: 1.6460 - accuracy: 0.2017 - val_loss: 1.6429 - val_accuracy: 0.1907\n",
      "Epoch 3/10\n",
      "55/55 [==============================] - 164s 3s/step - loss: 1.6231 - accuracy: 0.1983 - val_loss: 1.6422 - val_accuracy: 0.2040\n",
      "Epoch 4/10\n",
      "55/55 [==============================] - 159s 3s/step - loss: 1.6293 - accuracy: 0.2103 - val_loss: 1.6175 - val_accuracy: 0.2307\n",
      "Epoch 5/10\n",
      "55/55 [==============================] - 157s 3s/step - loss: 1.6195 - accuracy: 0.2011 - val_loss: 1.6159 - val_accuracy: 0.2307\n",
      "Epoch 6/10\n",
      "55/55 [==============================] - 154s 3s/step - loss: 1.6142 - accuracy: 0.2103 - val_loss: 1.6165 - val_accuracy: 0.2040\n",
      "Epoch 7/10\n",
      "55/55 [==============================] - 157s 3s/step - loss: 1.6149 - accuracy: 0.2137 - val_loss: 1.6146 - val_accuracy: 0.2307\n",
      "Epoch 8/10\n",
      "55/55 [==============================] - 214s 4s/step - loss: 1.6136 - accuracy: 0.2114 - val_loss: 1.6143 - val_accuracy: 0.2307\n",
      "Epoch 9/10\n",
      "55/55 [==============================] - 270s 5s/step - loss: 1.6139 - accuracy: 0.2097 - val_loss: 1.6088 - val_accuracy: 0.2307\n",
      "Epoch 10/10\n",
      "55/55 [==============================] - 245s 4s/step - loss: 1.6123 - accuracy: 0.2149 - val_loss: 1.6122 - val_accuracy: 0.2307\n",
      "79/79 [==============================] - 92s 1s/step - loss: 1.6081 - accuracy: 0.2292\n",
      "Model: 128-layer1-256-layer2-64-layer3-1704236162\n",
      "Test loss: 1.608066201210022\n",
      "Test accuracy: 0.22920000553131104\n",
      "Epoch 1/10\n",
      "55/55 [==============================] - 351s 6s/step - loss: 1.7115 - accuracy: 0.2080 - val_loss: 1.6121 - val_accuracy: 0.2307\n",
      "Epoch 2/10\n",
      "55/55 [==============================] - 323s 6s/step - loss: 1.5924 - accuracy: 0.2526 - val_loss: 1.6262 - val_accuracy: 0.2587\n",
      "Epoch 3/10\n",
      "55/55 [==============================] - 337s 6s/step - loss: 1.6173 - accuracy: 0.2229 - val_loss: 1.6300 - val_accuracy: 0.2013\n",
      "Epoch 4/10\n",
      "55/55 [==============================] - 216s 4s/step - loss: 1.6077 - accuracy: 0.2349 - val_loss: 1.6036 - val_accuracy: 0.2907\n",
      "Epoch 5/10\n",
      "55/55 [==============================] - 215s 4s/step - loss: 1.5848 - accuracy: 0.2731 - val_loss: 1.6696 - val_accuracy: 0.2360\n",
      "Epoch 6/10\n",
      "55/55 [==============================] - 208s 4s/step - loss: 1.5760 - accuracy: 0.2709 - val_loss: 1.6925 - val_accuracy: 0.2333\n",
      "Epoch 7/10\n",
      "55/55 [==============================] - 212s 4s/step - loss: 1.6006 - accuracy: 0.2709 - val_loss: 1.6772 - val_accuracy: 0.2067\n",
      "Epoch 8/10\n",
      "55/55 [==============================] - 214s 4s/step - loss: 1.6227 - accuracy: 0.2229 - val_loss: 1.6221 - val_accuracy: 0.2307\n",
      "Epoch 9/10\n",
      "55/55 [==============================] - 213s 4s/step - loss: 1.6121 - accuracy: 0.2171 - val_loss: 1.6253 - val_accuracy: 0.1773\n",
      "Epoch 10/10\n",
      "55/55 [==============================] - 202s 4s/step - loss: 1.6152 - accuracy: 0.1926 - val_loss: 1.6115 - val_accuracy: 0.2307\n",
      "79/79 [==============================] - 68s 859ms/step - loss: 1.6101 - accuracy: 0.2348\n",
      "Model: 128-layer1-256-layer2-128-layer3-1704238109\n",
      "Test loss: 1.6101336479187012\n",
      "Test accuracy: 0.23479999601840973\n",
      "Epoch 1/10\n",
      "55/55 [==============================] - 316s 6s/step - loss: 1.9418 - accuracy: 0.1771 - val_loss: 1.8891 - val_accuracy: 0.2013\n",
      "Epoch 2/10\n",
      "55/55 [==============================] - 310s 6s/step - loss: 1.6825 - accuracy: 0.2149 - val_loss: 1.6320 - val_accuracy: 0.2067\n",
      "Epoch 3/10\n",
      "55/55 [==============================] - 31334s 580s/step - loss: 1.6289 - accuracy: 0.1903 - val_loss: 1.6201 - val_accuracy: 0.2307\n",
      "Epoch 4/10\n",
      "55/55 [==============================] - 491s 9s/step - loss: 1.6231 - accuracy: 0.2206 - val_loss: 1.6154 - val_accuracy: 0.2307\n",
      "Epoch 5/10\n",
      "55/55 [==============================] - 571s 10s/step - loss: 1.6201 - accuracy: 0.1937 - val_loss: 1.6263 - val_accuracy: 0.2013\n",
      "Epoch 6/10\n",
      "55/55 [==============================] - 594s 11s/step - loss: 1.6229 - accuracy: 0.2040 - val_loss: 1.6113 - val_accuracy: 0.2307\n",
      "Epoch 7/10\n",
      "55/55 [==============================] - 531s 10s/step - loss: 1.6172 - accuracy: 0.2051 - val_loss: 1.6100 - val_accuracy: 0.2307\n",
      "Epoch 8/10\n",
      "55/55 [==============================] - 544s 10s/step - loss: 1.6157 - accuracy: 0.1994 - val_loss: 1.6076 - val_accuracy: 0.2307\n",
      "Epoch 9/10\n",
      "55/55 [==============================] - 537s 10s/step - loss: 1.6147 - accuracy: 0.2103 - val_loss: 1.6077 - val_accuracy: 0.2307\n",
      "Epoch 10/10\n",
      "55/55 [==============================] - 333s 6s/step - loss: 1.6161 - accuracy: 0.1903 - val_loss: 1.6072 - val_accuracy: 0.2307\n",
      "79/79 [==============================] - 104s 1s/step - loss: 1.6066 - accuracy: 0.2292\n",
      "Model: 128-layer1-256-layer2-256-layer3-1704240672\n",
      "Test loss: 1.6066044569015503\n",
      "Test accuracy: 0.22920000553131104\n",
      "Epoch 1/10\n",
      "55/55 [==============================] - 278s 5s/step - loss: 1.7654 - accuracy: 0.2040 - val_loss: 1.6351 - val_accuracy: 0.2000\n",
      "Epoch 2/10\n",
      "55/55 [==============================] - 440s 8s/step - loss: 1.6239 - accuracy: 0.2154 - val_loss: 1.6159 - val_accuracy: 0.2307\n",
      "Epoch 3/10\n",
      "55/55 [==============================] - 510s 9s/step - loss: 1.6183 - accuracy: 0.2114 - val_loss: 1.6319 - val_accuracy: 0.2307\n",
      "Epoch 4/10\n",
      "55/55 [==============================] - 575s 10s/step - loss: 1.6163 - accuracy: 0.2006 - val_loss: 1.6277 - val_accuracy: 0.1773\n",
      "Epoch 5/10\n",
      "55/55 [==============================] - 2512s 46s/step - loss: 1.6198 - accuracy: 0.1954 - val_loss: 1.6132 - val_accuracy: 0.2307\n",
      "Epoch 6/10\n",
      "55/55 [==============================] - 407s 7s/step - loss: 1.6125 - accuracy: 0.2114 - val_loss: 1.6184 - val_accuracy: 0.2000\n",
      "Epoch 7/10\n",
      "55/55 [==============================] - 444s 8s/step - loss: 1.6134 - accuracy: 0.1960 - val_loss: 1.6147 - val_accuracy: 0.2040\n",
      "Epoch 8/10\n",
      "55/55 [==============================] - 431s 8s/step - loss: 1.6149 - accuracy: 0.2154 - val_loss: 1.6106 - val_accuracy: 0.2307\n",
      "Epoch 9/10\n",
      "55/55 [==============================] - 387s 7s/step - loss: 1.6147 - accuracy: 0.1960 - val_loss: 1.6192 - val_accuracy: 0.1827\n",
      "Epoch 10/10\n",
      "55/55 [==============================] - 415s 8s/step - loss: 1.6122 - accuracy: 0.2023 - val_loss: 1.6273 - val_accuracy: 0.2000\n",
      "79/79 [==============================] - 121s 2s/step - loss: 1.6158 - accuracy: 0.2060\n",
      "Model: 256-layer1-64-layer2-64-layer3-1704276341\n",
      "Test loss: 1.6157574653625488\n",
      "Test accuracy: 0.20600000023841858\n",
      "Epoch 1/10\n",
      "55/55 [==============================] - 509s 9s/step - loss: 1.7347 - accuracy: 0.1851 - val_loss: 1.6218 - val_accuracy: 0.1773\n",
      "Epoch 2/10\n",
      "55/55 [==============================] - 456s 8s/step - loss: 1.6223 - accuracy: 0.1983 - val_loss: 1.6098 - val_accuracy: 0.2307\n",
      "Epoch 3/10\n",
      "55/55 [==============================] - 430s 8s/step - loss: 1.6209 - accuracy: 0.2091 - val_loss: 1.6199 - val_accuracy: 0.1773\n",
      "Epoch 4/10\n",
      "55/55 [==============================] - 541s 10s/step - loss: 1.6226 - accuracy: 0.1926 - val_loss: 1.6136 - val_accuracy: 0.2307\n",
      "Epoch 5/10\n",
      "55/55 [==============================] - 445s 8s/step - loss: 1.6210 - accuracy: 0.2109 - val_loss: 1.6120 - val_accuracy: 0.2307\n",
      "Epoch 6/10\n",
      "55/55 [==============================] - 485s 9s/step - loss: 1.6195 - accuracy: 0.2011 - val_loss: 1.6134 - val_accuracy: 0.2013\n",
      "Epoch 7/10\n",
      "55/55 [==============================] - 527s 10s/step - loss: 1.6175 - accuracy: 0.2131 - val_loss: 1.6103 - val_accuracy: 0.2307\n",
      "Epoch 8/10\n",
      "55/55 [==============================] - 544s 10s/step - loss: 1.6186 - accuracy: 0.2177 - val_loss: 1.6084 - val_accuracy: 0.2307\n",
      "Epoch 9/10\n",
      "55/55 [==============================] - 560s 10s/step - loss: 1.6170 - accuracy: 0.1920 - val_loss: 1.6174 - val_accuracy: 0.1773\n",
      "Epoch 10/10\n",
      "55/55 [==============================] - 482s 9s/step - loss: 1.6202 - accuracy: 0.2023 - val_loss: 1.6080 - val_accuracy: 0.2307\n",
      "79/79 [==============================] - 88s 1s/step - loss: 1.6043 - accuracy: 0.2292\n",
      "Model: 256-layer1-64-layer2-128-layer3-1704282864\n",
      "Test loss: 1.60429847240448\n",
      "Test accuracy: 0.22920000553131104\n",
      "Epoch 1/10\n",
      "55/55 [==============================] - 528s 9s/step - loss: 1.7187 - accuracy: 0.2109 - val_loss: 1.6304 - val_accuracy: 0.2307\n",
      "Epoch 2/10\n",
      "55/55 [==============================] - 420s 8s/step - loss: 1.6333 - accuracy: 0.2057 - val_loss: 1.6270 - val_accuracy: 0.2067\n",
      "Epoch 3/10\n",
      "55/55 [==============================] - 409s 7s/step - loss: 1.6273 - accuracy: 0.1989 - val_loss: 1.6195 - val_accuracy: 0.2067\n",
      "Epoch 4/10\n",
      "55/55 [==============================] - 437s 8s/step - loss: 1.6292 - accuracy: 0.1989 - val_loss: 1.6379 - val_accuracy: 0.1773\n",
      "Epoch 5/10\n",
      "55/55 [==============================] - 524s 10s/step - loss: 1.6264 - accuracy: 0.1983 - val_loss: 1.6221 - val_accuracy: 0.2040\n",
      "Epoch 6/10\n",
      "55/55 [==============================] - 792s 14s/step - loss: 1.6216 - accuracy: 0.2029 - val_loss: 1.6224 - val_accuracy: 0.1773\n",
      "Epoch 7/10\n",
      "55/55 [==============================] - 783s 14s/step - loss: 1.6190 - accuracy: 0.2080 - val_loss: 1.6134 - val_accuracy: 0.1840\n",
      "Epoch 8/10\n",
      "55/55 [==============================] - 777s 14s/step - loss: 1.6253 - accuracy: 0.1920 - val_loss: 1.6109 - val_accuracy: 0.2013\n",
      "Epoch 9/10\n",
      "55/55 [==============================] - 794s 14s/step - loss: 1.6160 - accuracy: 0.2114 - val_loss: 1.6069 - val_accuracy: 0.2307\n",
      "Epoch 10/10\n",
      "55/55 [==============================] - 1081s 20s/step - loss: 1.6227 - accuracy: 0.2086 - val_loss: 1.6162 - val_accuracy: 0.2013\n",
      "79/79 [==============================] - 154s 2s/step - loss: 1.6082 - accuracy: 0.2060\n",
      "Model: 256-layer1-64-layer2-256-layer3-1704287934\n",
      "Test loss: 1.6082239151000977\n",
      "Test accuracy: 0.20600000023841858\n",
      "Epoch 1/10\n",
      "55/55 [==============================] - 550s 10s/step - loss: 1.7401 - accuracy: 0.1960 - val_loss: 1.6279 - val_accuracy: 0.2307\n",
      "Epoch 2/10\n",
      "55/55 [==============================] - 892s 16s/step - loss: 1.6302 - accuracy: 0.2023 - val_loss: 1.6209 - val_accuracy: 0.1947\n",
      "Epoch 3/10\n",
      "55/55 [==============================] - 314s 6s/step - loss: 1.6167 - accuracy: 0.2063 - val_loss: 1.6193 - val_accuracy: 0.2000\n",
      "Epoch 4/10\n",
      "55/55 [==============================] - 249s 5s/step - loss: 1.6177 - accuracy: 0.1994 - val_loss: 1.6137 - val_accuracy: 0.1947\n",
      "Epoch 5/10\n",
      "55/55 [==============================] - 248s 5s/step - loss: 1.6184 - accuracy: 0.2069 - val_loss: 1.6290 - val_accuracy: 0.1947\n",
      "Epoch 6/10\n",
      "55/55 [==============================] - 249s 5s/step - loss: 1.6159 - accuracy: 0.2103 - val_loss: 1.6187 - val_accuracy: 0.1773\n",
      "Epoch 7/10\n",
      "55/55 [==============================] - 250s 5s/step - loss: 1.6192 - accuracy: 0.2011 - val_loss: 1.6134 - val_accuracy: 0.2307\n",
      "Epoch 8/10\n",
      "55/55 [==============================] - 239s 4s/step - loss: 1.6152 - accuracy: 0.2160 - val_loss: 1.6113 - val_accuracy: 0.2053\n",
      "Epoch 9/10\n",
      "55/55 [==============================] - 13135s 243s/step - loss: 1.6140 - accuracy: 0.2149 - val_loss: 1.6217 - val_accuracy: 0.1773\n",
      "Epoch 10/10\n",
      "55/55 [==============================] - 468s 9s/step - loss: 1.6153 - accuracy: 0.2006 - val_loss: 1.6123 - val_accuracy: 0.1947\n",
      "79/79 [==============================] - 135s 2s/step - loss: 1.6120 - accuracy: 0.2044\n",
      "Model: 256-layer1-128-layer2-64-layer3-1704294637\n",
      "Test loss: 1.6119736433029175\n",
      "Test accuracy: 0.20440000295639038\n",
      "Epoch 1/10\n",
      "55/55 [==============================] - 534s 9s/step - loss: 1.7230 - accuracy: 0.2086 - val_loss: 1.6475 - val_accuracy: 0.1773\n",
      "Epoch 2/10\n",
      "55/55 [==============================] - 529s 10s/step - loss: 1.6271 - accuracy: 0.2057 - val_loss: 1.6136 - val_accuracy: 0.2067\n",
      "Epoch 3/10\n",
      "55/55 [==============================] - 329s 6s/step - loss: 1.6232 - accuracy: 0.2149 - val_loss: 1.6133 - val_accuracy: 0.2307\n",
      "Epoch 4/10\n",
      "55/55 [==============================] - 287s 5s/step - loss: 1.6249 - accuracy: 0.2080 - val_loss: 1.6181 - val_accuracy: 0.1840\n",
      "Epoch 5/10\n",
      "55/55 [==============================] - 285s 5s/step - loss: 1.6224 - accuracy: 0.2080 - val_loss: 1.6332 - val_accuracy: 0.2307\n",
      "Epoch 6/10\n",
      "55/55 [==============================] - 277s 5s/step - loss: 1.6227 - accuracy: 0.1994 - val_loss: 1.6204 - val_accuracy: 0.2307\n",
      "Epoch 7/10\n",
      "55/55 [==============================] - 276s 5s/step - loss: 1.6189 - accuracy: 0.2051 - val_loss: 1.6148 - val_accuracy: 0.2013\n",
      "Epoch 8/10\n",
      "55/55 [==============================] - 301s 5s/step - loss: 1.6193 - accuracy: 0.2143 - val_loss: 1.6151 - val_accuracy: 0.2013\n",
      "Epoch 9/10\n",
      "55/55 [==============================] - 509s 9s/step - loss: 1.6208 - accuracy: 0.1886 - val_loss: 1.6073 - val_accuracy: 0.2067\n",
      "Epoch 10/10\n",
      "55/55 [==============================] - 523s 9s/step - loss: 1.6198 - accuracy: 0.1914 - val_loss: 1.6086 - val_accuracy: 0.2307\n",
      "79/79 [==============================] - 130s 2s/step - loss: 1.6139 - accuracy: 0.2292\n",
      "Model: 256-layer1-128-layer2-128-layer3-1704311370\n",
      "Test loss: 1.6139459609985352\n",
      "Test accuracy: 0.22920000553131104\n",
      "Epoch 1/10\n",
      "55/55 [==============================] - 764s 14s/step - loss: 1.7063 - accuracy: 0.2143 - val_loss: 1.6092 - val_accuracy: 0.2520\n",
      "Epoch 2/10\n",
      "55/55 [==============================] - 647s 12s/step - loss: 1.6192 - accuracy: 0.2446 - val_loss: 1.6190 - val_accuracy: 0.2067\n",
      "Epoch 3/10\n",
      "55/55 [==============================] - 439s 8s/step - loss: 1.6353 - accuracy: 0.2080 - val_loss: 1.6242 - val_accuracy: 0.1907\n",
      "Epoch 4/10\n",
      "55/55 [==============================] - 967s 18s/step - loss: 1.6195 - accuracy: 0.2114 - val_loss: 1.6253 - val_accuracy: 0.2120\n",
      "Epoch 5/10\n",
      "55/55 [==============================] - 658s 12s/step - loss: 1.6158 - accuracy: 0.2303 - val_loss: 1.6408 - val_accuracy: 0.1853\n",
      "Epoch 6/10\n",
      "55/55 [==============================] - 696s 13s/step - loss: 1.6173 - accuracy: 0.2011 - val_loss: 1.5980 - val_accuracy: 0.2560\n",
      "Epoch 7/10\n",
      "55/55 [==============================] - 652s 12s/step - loss: 1.6147 - accuracy: 0.2183 - val_loss: 1.6110 - val_accuracy: 0.1987\n",
      "Epoch 8/10\n",
      "55/55 [==============================] - 665s 12s/step - loss: 1.6125 - accuracy: 0.2366 - val_loss: 1.6243 - val_accuracy: 0.2013\n",
      "Epoch 9/10\n",
      "55/55 [==============================] - 618s 11s/step - loss: 1.6179 - accuracy: 0.2074 - val_loss: 1.6139 - val_accuracy: 0.2307\n",
      "Epoch 10/10\n",
      "55/55 [==============================] - 677s 12s/step - loss: 1.6129 - accuracy: 0.2257 - val_loss: 1.6351 - val_accuracy: 0.1960\n",
      "79/79 [==============================] - 156s 2s/step - loss: 1.6292 - accuracy: 0.2216\n",
      "Model: 256-layer1-128-layer2-256-layer3-1704315355\n",
      "Test loss: 1.6292225122451782\n",
      "Test accuracy: 0.2215999960899353\n",
      "Epoch 1/10\n",
      "55/55 [==============================] - 1029s 18s/step - loss: 1.7175 - accuracy: 0.2063 - val_loss: 1.6188 - val_accuracy: 0.1773\n",
      "Epoch 2/10\n",
      "55/55 [==============================] - 997s 18s/step - loss: 1.6192 - accuracy: 0.2023 - val_loss: 1.6165 - val_accuracy: 0.2013\n",
      "Epoch 3/10\n",
      "55/55 [==============================] - 1085s 20s/step - loss: 1.6157 - accuracy: 0.2137 - val_loss: 1.6126 - val_accuracy: 0.2307\n",
      "Epoch 4/10\n",
      "55/55 [==============================] - 511s 9s/step - loss: 1.7020 - accuracy: 0.2029 - val_loss: 1.6346 - val_accuracy: 0.2200\n",
      "Epoch 5/10\n",
      "55/55 [==============================] - 523s 10s/step - loss: 1.6261 - accuracy: 0.2160 - val_loss: 1.6192 - val_accuracy: 0.2013\n",
      "Epoch 6/10\n",
      "55/55 [==============================] - 511s 9s/step - loss: 1.6160 - accuracy: 0.1960 - val_loss: 1.6284 - val_accuracy: 0.1773\n",
      "Epoch 7/10\n",
      "55/55 [==============================] - 521s 9s/step - loss: 1.6163 - accuracy: 0.1834 - val_loss: 1.6111 - val_accuracy: 0.2160\n",
      "Epoch 8/10\n",
      "55/55 [==============================] - 513s 9s/step - loss: 1.6135 - accuracy: 0.1920 - val_loss: 1.6033 - val_accuracy: 0.2427\n",
      "Epoch 9/10\n",
      "55/55 [==============================] - 538s 10s/step - loss: 1.6154 - accuracy: 0.2126 - val_loss: 1.6073 - val_accuracy: 0.2027\n",
      "Epoch 10/10\n",
      "55/55 [==============================] - 1138s 21s/step - loss: 1.6139 - accuracy: 0.2194 - val_loss: 1.6308 - val_accuracy: 0.1747\n",
      "79/79 [==============================] - 200s 3s/step - loss: 1.6255 - accuracy: 0.2056\n",
      "Model: 256-layer1-256-layer2-64-layer3-1704322299\n",
      "Test loss: 1.6254819631576538\n",
      "Test accuracy: 0.20559999346733093\n",
      "Epoch 1/10\n",
      "55/55 [==============================] - 1130s 20s/step - loss: 1.7144 - accuracy: 0.2171 - val_loss: 1.6299 - val_accuracy: 0.2307\n",
      "Epoch 2/10\n",
      "55/55 [==============================] - 1025s 19s/step - loss: 1.6363 - accuracy: 0.2011 - val_loss: 1.6067 - val_accuracy: 0.2333\n",
      "Epoch 3/10\n",
      "55/55 [==============================] - 862s 16s/step - loss: 1.6168 - accuracy: 0.2166 - val_loss: 1.6131 - val_accuracy: 0.2293\n",
      "Epoch 4/10\n",
      "55/55 [==============================] - 597s 11s/step - loss: 1.8054 - accuracy: 0.1960 - val_loss: 1.6547 - val_accuracy: 0.2307\n",
      "Epoch 5/10\n",
      "55/55 [==============================] - 572s 10s/step - loss: 1.6354 - accuracy: 0.2029 - val_loss: 1.6174 - val_accuracy: 0.2013\n",
      "Epoch 6/10\n",
      "55/55 [==============================] - 38350s 710s/step - loss: 1.6247 - accuracy: 0.2091 - val_loss: 1.6128 - val_accuracy: 0.2067\n",
      "Epoch 7/10\n",
      "55/55 [==============================] - 690s 12s/step - loss: 1.6169 - accuracy: 0.2166 - val_loss: 1.6153 - val_accuracy: 0.2013\n",
      "Epoch 8/10\n",
      "55/55 [==============================] - 621s 11s/step - loss: 1.6137 - accuracy: 0.2143 - val_loss: 1.6115 - val_accuracy: 0.2307\n",
      "Epoch 9/10\n",
      "12/55 [=====>........................] - ETA: 15:16 - loss: 1.6202 - accuracy: 0.2057"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\projects\\Pattern-Recognition\\Team28-D.ipynb Cell 30\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/projects/Pattern-Recognition/Team28-D.ipynb#Y134sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m X_test_reshaped \u001b[39m=\u001b[39m X_test\u001b[39m.\u001b[39mreshape((X_test\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], X_test\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], \u001b[39m1\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/projects/Pattern-Recognition/Team28-D.ipynb#Y134sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39m# Train the model with 10 epochs, 30% validation split, and TensorBoard callback\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/projects/Pattern-Recognition/Team28-D.ipynb#Y134sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train_reshaped, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.3\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[tensorboard_callback])\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/projects/Pattern-Recognition/Team28-D.ipynb#Y134sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39m# Evaluate the model on the test set\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/projects/Pattern-Recognition/Team28-D.ipynb#Y134sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m test_loss, test_acc \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(X_test_reshaped, y_test)\n",
      "File \u001b[1;32mc:\\Users\\Elena\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Elena\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1776\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1777\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1780\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1781\u001b[0m ):\n\u001b[0;32m   1782\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1783\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1784\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1785\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Elena\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Elena\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Elena\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    864\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    865\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    866\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    868\u001b[0m       args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_config\n\u001b[0;32m    869\u001b[0m   )\n\u001b[0;32m    870\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    872\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Elena\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Elena\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1261\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1262\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1263\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1264\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mflat_call(args)\n\u001b[0;32m   1265\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1266\u001b[0m     args,\n\u001b[0;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1268\u001b[0m     executing_eagerly)\n\u001b[0;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Elena\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_call\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    216\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    218\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\Elena\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[0;32m    251\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 252\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    253\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    254\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[0;32m    255\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[0;32m    256\u001b[0m     )\n\u001b[0;32m    257\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    259\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m    260\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[0;32m    261\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[0;32m    262\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Elena\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1477\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[0;32m   1478\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1479\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1480\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1481\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[0;32m   1482\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[0;32m   1483\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1484\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1485\u001b[0m   )\n\u001b[0;32m   1486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1487\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1488\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1489\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1493\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[0;32m   1494\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\Elena\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.callbacks import TensorBoard\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data from CSV file\n",
    "data = pd.read_csv(r\"D:\\projects\\Pattern-Recognition\\datasetC.csv\", header=None)\n",
    "\n",
    "# Preprocess data by converting it to NumPy array\n",
    "data = data.values\n",
    "X = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "# Define hyperparameters and architecture variations\n",
    "layer_sizes = [64, 128, 256]\n",
    "\n",
    "# Experiment loop for different layer sizes\n",
    "for layer1_size in layer_sizes:\n",
    "    for layer2_size in layer_sizes:\n",
    "        for layer3_size in layer_sizes:\n",
    "            # Generate a unique name for each experiment based on timestamp\n",
    "            NAME = \"{}-layer1-{}-layer2-{}-layer3-{}\".format(\n",
    "                layer1_size, layer2_size, layer3_size, int(time.time())\n",
    "            )\n",
    "            \n",
    "            logdir = os.path.join(\"logs\", NAME)\n",
    "            tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "            # Build the sequential model with LSTM layers\n",
    "            model = Sequential()\n",
    "            model.add(LSTM(layer1_size, input_shape=(X_train.shape[1], 1), return_sequences=True))\n",
    "            model.add(LSTM(layer2_size, return_sequences=True))\n",
    "            model.add(LSTM(layer3_size))\n",
    "            model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "            # Compile the model with Adam optimizSer and categorical crossentropy loss\n",
    "            model.compile(optimizer='adam',\n",
    "                          loss='sparse_categorical_crossentropy',\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "            # Reshape input data for LSTM layer\n",
    "            X_train_reshaped = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "            X_test_reshaped = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "            # Train the model with 10 epochs, 30% validation split, and TensorBoard callback\n",
    "            model.fit(X_train_reshaped, y_train, epochs=10, validation_split=0.3, callbacks=[tensorboard_callback])\n",
    "\n",
    "            # Evaluate the model on the test set\n",
    "            test_loss, test_acc = model.evaluate(X_test_reshaped, y_test)\n",
    "            \n",
    "            # Print results for each experiment\n",
    "            print(f'Model: {NAME}')\n",
    "            print(f'Test loss: {test_loss}')\n",
    "            print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'kill' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our investigation the experiment that provided the best accuracy results on the validating data with the accuracy of {add the % accuracy} is the following. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pedict our model and save our data to a npy file named `labels28.npy`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the unlabeled test data\n",
    "test_data = pd.read_csv(r\"D:\\projects\\Pattern-Recognition\\datasetCTest.csv\", header=None)\n",
    "\n",
    "# Apply the trained model to the unlabeled test data\n",
    "labels28 = np.argmax(model.predict(test_data.values), axis=1)\n",
    "\n",
    "# Save the labelsX vector in numpy format\n",
    "np.save('labels28.npy', labels28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load our labels to make sure everything works well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the labels28 vector\n",
    "labels28 = np.load('labels28.npy')\n",
    "\n",
    "# Print labels28 vector \n",
    "print(labels28)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
